{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6409a884",
   "metadata": {},
   "source": [
    "- cache() - a PySpark optimization method that stores a DataFrame (or RDD) in memory (executor RAM) after the first action triggers its computation.\n",
    "- It avoids recomputing the DataFrame for subsequent actions, improving performance.\n",
    "\n",
    "- Key Points: -\n",
    "    - Stores data in executor memory (not driver memory)\n",
    "    - Lazy eveluation: cache() takes effect only after an action (e.g., show(), count()),\n",
    "    - If executor memory is insufficient, Spark may evict partitions and recompute them.\n",
    "    - cache() is shorthand for persist (StorageLevel.MEMORY_AND_DISK).\n",
    "\n",
    "- Benefits of cache(): -\n",
    "    - 1. Speeds up jobs when reusing the same DataFrame.\n",
    "    - 2. Saves recomputation time in iterative algorithms (ML, Graph Processing).\n",
    "    - 3. Useful for Exploratory Data Analysis (EDA).\n",
    "    - 4. Optimizes performance in joins where a DataFrame is reused.\n",
    "\n",
    "- Basic Architechture:\n",
    "| -- | -- | -- |\n",
    "| Driver | -> | Executors |\n",
    "| sends tasks | -- | Executes tasks |\n",
    "| no cacheing | -- | caches data in memory |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cba2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "spark = SparkSession.builder.appName(\"cacheExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42371d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Manta\", 75000, \"IT\", 24),\n",
    "    (2, \"Dipankar\", 30000, \"Post Master\", 27),\n",
    "    (3, \"Souvik\", 60000, \"Army Officer\", 27),\n",
    "    (4, \"Soukarjya\", 45000, \"BDO\", 26),\n",
    "    (5, \"Arvind\", 35000, \"Business Data Analyst\", 28),\n",
    "    (6, \"Prodipta\", 25000, \"Data Analyst\", 28),\n",
    "    (7, \"Padma\", 20000, \"Data Analyst\", 27),\n",
    "    (8, \"Panta\", 125000, \"Business Analyst\", 27)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\", \"salary\", \"department\", \"age\"])\n",
    "\n",
    "# show full DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7cf7e",
   "metadata": {},
   "source": [
    "#### Cache the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply cache()\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96feea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger an action to materialize the cache\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2d30e",
   "metadata": {},
   "source": [
    "- Explanation:\n",
    "    1. after the first action (count), Spark stores partitions of 'df' in executor memory.\n",
    "    2. Future actions reuse the cache data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64139ff",
   "metadata": {},
   "source": [
    "#### Perform Actions on Cached Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show DataFrame (faster after caching)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce21595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter records where age>27\n",
    "df.filter(df.age > 28).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by age and coumt\n",
    "df.groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex query example\n",
    "df.select(\"name\", \"age\") \\\n",
    "    . filter(df.age >= 30) \\\n",
    "    .orderBy(\"age\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if DataFrame is cached\n",
    "print(\"Is DataFrame cached? \", df.is_cached)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de70860",
   "metadata": {},
   "source": [
    "#### Remove Cache (Unpersist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d83343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up executor memory\n",
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae844e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm cache removal\n",
    "print(\"Is DataFrame cached after unpersist? \", df.is_cached)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c905e",
   "metadata": {},
   "source": [
    "#### When to use cache()? (Real-world scenarios)\n",
    "- Reusing DataFrame in multiple actions/transforms\n",
    "- EDA workflows with repeated filtering/grouping\n",
    "- ML pipelines with repeated training dataaccess\n",
    "- Repeated joins with the same lookup DataFrame\n",
    "- Iterative graph algorithms (e.g. PageRank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f758d",
   "metadata": {},
   "source": [
    "#### Best Practices\n",
    "- Trigger an action after cache() to store data\n",
    "- Monitor Spark UI > Storage tab for cache status.\n",
    "- Use unpersist() when caching is no longer needed.\n",
    "- Use persist() if fine-grained control (disk/memory) is required.\n",
    "- Avoid caching large DataFrames unnecessarily to prevent OOM issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb22216",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "- cache() stores data in executor memory for faster access.\n",
    "- reduces recomputation time in Spark workflows.\n",
    "- requires an action (e.g., count()) to trigger caching.\n",
    "- use unpersist() to manage memory effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81393b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
